// Session class for OpenAI Realtime API
class Session {
    constructor(apiKey, streamType) {
        this.apiKey = apiKey;
        this.streamType = streamType;
        this.useSessionToken = true;
        this.ms = null;
        this.pc = null;
        this.dc = null;
        this.muted = false;
    }

    async start(stream, sessionConfig) {
        await this.startInternal(stream, sessionConfig, "/v1/realtime/sessions");
    }

    async startTranscription(stream, sessionConfig) {
        await this.startInternal(stream, sessionConfig, "/v1/realtime/transcription_sessions");
    }

    stop() {
        this.dc?.close();
        this.dc = null;
        this.pc?.close();
        this.pc = null;
        this.ms?.getTracks().forEach(t => t.stop());
        this.ms = null;
        this.muted = false;
    }

    mute(muted) {
        this.muted = muted;
        this.pc.getSenders().forEach(sender => sender.track.enabled = !muted);
    }

    async startInternal(stream, sessionConfig, tokenEndpoint) {
        this.ms = stream;
        this.pc = new RTCPeerConnection();
        this.pc.ontrack = (e) => this.ontrack?.(e);
        this.pc.addTrack(stream.getTracks()[0]);
        this.pc.onconnectionstatechange = () => this.onconnectionstatechange?.(this.pc.connectionState);
        this.dc = this.pc.createDataChannel("");
        this.dc.onopen = (e) => this.onopen?.();
        this.dc.onmessage = (e) => this.onmessage?.(JSON.parse(e.data));

        const offer = await this.pc.createOffer();
        await this.pc.setLocalDescription(offer);
        try {
            const answer = await this.signal(offer, sessionConfig, tokenEndpoint);
            await this.pc.setRemoteDescription(answer);
        } catch (e) {
            this.onerror?.(e);
        }
    }

    async signal(offer, sessionConfig, tokenEndpoint) {
        const urlRoot = "https://api.openai.com";
        const realtimeUrl = `${urlRoot}/v1/realtime`;
        let sdpResponse;
        if (this.useSessionToken) {
            const sessionUrl = `${urlRoot}${tokenEndpoint}`;
            const sessionResponse = await fetch(sessionUrl, {
                method: "POST",
                headers: {
                    Authorization: `Bearer ${this.apiKey}`,
                    "openai-beta": "realtime-v1",
                    "Content-Type": "application/json"
                },
                body: JSON.stringify(sessionConfig),
            });
            if (!sessionResponse.ok) {
                throw new Error("Failed to request session token");
            }
            const sessionData = await sessionResponse.json();
            const clientSecret = sessionData.client_secret.value;
            sdpResponse = await fetch(`${realtimeUrl}`, {
                method: "POST",
                body: offer.sdp,
                headers: {
                    Authorization: `Bearer ${clientSecret}`,
                    "Content-Type": "application/sdp"
                },
            });
            if (!sdpResponse.ok) {
                throw new Error("Failed to signal");
            }
        } else {
            const formData = new FormData();
            formData.append("session", JSON.stringify(sessionConfig));
            formData.append("sdp", offer.sdp);
            sdpResponse = await fetch(`${realtimeUrl}`, {
                method: "POST",
                body: formData,
                headers: { Authorization: `Bearer ${this.apiKey}` },
            });
            if (!sdpResponse.ok) {
                throw new Error("Failed to signal");
            }
        }
        return { type: "answer", sdp: await sdpResponse.text() };
    }

    sendMessage(message) {
        this.dc.send(JSON.stringify(message));
    }
}

// WAV Recorder class
class WavRecorder {
    constructor() {
        this.mediaRecorder = null;
        this.audioChunks = [];
        this.isRecording = false;
        this.combinedStream = null;
    }

    async startRecording(microphoneStream, systemAudioStream) {
        if (this.isRecording) return;

        try {
            // Create audio context to mix streams
            const audioContext = new AudioContext();

            // Create sources for both streams
            const micSource = audioContext.createMediaStreamSource(microphoneStream);
            const systemSource = audioContext.createMediaStreamSource(systemAudioStream);

            // Create a merger to combine the audio
            const merger = audioContext.createChannelMerger(2);

            // Connect both sources to the merger
            micSource.connect(merger, 0, 0);
            systemSource.connect(merger, 0, 1);

            // Create a destination stream
            const destination = audioContext.createMediaStreamDestination();
            merger.connect(destination);

            this.combinedStream = destination.stream;

            // Start recording
            this.mediaRecorder = new MediaRecorder(this.combinedStream, {
                mimeType: 'audio/webm;codecs=opus'
            });

            this.audioChunks = [];
            this.isRecording = true;

            this.mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    this.audioChunks.push(event.data);
                }
            };

            this.mediaRecorder.onstop = () => {
                this.saveRecording();
            };

            this.mediaRecorder.start(1000); // Collect data every second
            console.log('WAV recording started');

        } catch (error) {
            console.error('Error starting WAV recording:', error);
            throw error;
        }
    }

    stopRecording() {
        if (!this.isRecording || !this.mediaRecorder) return;

        this.mediaRecorder.stop();
        this.isRecording = false;
        console.log('WAV recording stopped');
    }

    async saveRecording() {
        if (this.audioChunks.length === 0) return;

        try {
            // Convert to WAV format
            const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
            const arrayBuffer = await audioBlob.arrayBuffer();

            // Convert to WAV using Web Audio API
            const audioContext = new AudioContext();
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

            // Create WAV file
            const wavBlob = this.audioBufferToWav(audioBuffer);

            // Save file
            const url = URL.createObjectURL(wavBlob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `recording_${new Date().toISOString().replace(/[:.]/g, '-')}.wav`;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);

            console.log('WAV file saved');

        } catch (error) {
            console.error('Error saving WAV recording:', error);
        }
    }

    audioBufferToWav(buffer) {
        const length = buffer.length;
        const numberOfChannels = buffer.numberOfChannels;
        const sampleRate = buffer.sampleRate;
        const arrayBuffer = new ArrayBuffer(44 + length * numberOfChannels * 2);
        const view = new DataView(arrayBuffer);

        // WAV header
        const writeString = (offset, string) => {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        };

        writeString(0, 'RIFF');
        view.setUint32(4, 36 + length * numberOfChannels * 2, true);
        writeString(8, 'WAVE');
        writeString(12, 'fmt ');
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);
        view.setUint16(22, numberOfChannels, true);
        view.setUint32(24, sampleRate, true);
        view.setUint32(28, sampleRate * numberOfChannels * 2, true);
        view.setUint16(32, numberOfChannels * 2, true);
        view.setUint16(34, 16, true);
        writeString(36, 'data');
        view.setUint32(40, length * numberOfChannels * 2, true);

        // Write audio data
        let offset = 44;
        for (let i = 0; i < length; i++) {
            for (let channel = 0; channel < numberOfChannels; channel++) {
                const sample = Math.max(-1, Math.min(1, buffer.getChannelData(channel)[i]));
                view.setInt16(offset, sample * 0x7FFF, true);
                offset += 2;
            }
        }

        return new Blob([arrayBuffer], { type: 'audio/wav' });
    }
}

// Playbook Management System
class PlaybookManager {
    constructor() {
        this.documents = new Map();
        this.categories = {
            objections: [],
            scripts: [],
            cases: [],
            questions: []
        };
        this.searchIndex = null;
        this.isEnabled = window.electronAPI?.playbook?.enabled || false;
        this.config = window.electronAPI?.playbook || {};
        this.init();
    }

    init() {
        if (!this.isEnabled) {
            console.log('Playbook system disabled via .env');
            return;
        }

        this.setupUI();
        this.loadStoredDocuments();
        this.updateStatus('Sistema ativado - Pronto para receber documentos');
    }

    setupUI() {
        const panel = document.getElementById('playbookPanel');
        if (panel) {
            panel.classList.add('enabled');
        }

        // Update supported types and max size from config
        const typesElement = document.getElementById('supportedTypes');
        const maxSizeElement = document.getElementById('maxSize');
        
        if (typesElement) {
            typesElement.textContent = this.config.allowedTypes?.join(', ').toUpperCase() || 'PDF, DOCX, TXT';
        }
        
        if (maxSizeElement) {
            maxSizeElement.textContent = `M√°x ${this.config.maxFileSize || '10MB'}`;
        }

        // Setup event listeners
        this.setupEventListeners();
    }

    setupEventListeners() {
        const uploadBtn = document.getElementById('uploadBtn');
        const fileInput = document.getElementById('fileInput');
        const uploadSection = document.getElementById('uploadSection');

        if (uploadBtn && fileInput) {
            uploadBtn.addEventListener('click', () => fileInput.click());
            fileInput.addEventListener('change', (e) => this.handleFileUpload(e.target.files));
        }

        if (uploadSection) {
            uploadSection.addEventListener('dragover', (e) => {
                e.preventDefault();
                uploadSection.classList.add('drag-over');
            });

            uploadSection.addEventListener('dragleave', () => {
                uploadSection.classList.remove('drag-over');
            });

            uploadSection.addEventListener('drop', (e) => {
                e.preventDefault();
                uploadSection.classList.remove('drag-over');
                this.handleFileUpload(e.dataTransfer.files);
            });
        }
    }

    async handleFileUpload(files) {
        this.updateStatus('Processando arquivos...');
        
        for (const file of files) {
            try {
                await this.processFile(file);
            } catch (error) {
                console.error('Error processing file:', file.name, error);
                this.updateStatus(`Erro ao processar ${file.name}: ${error.message}`);
            }
        }
        
        this.updateStatus('Documentos processados com sucesso');
        this.updateCategoryCounts();
        this.renderDocumentsList();
    }

    async processFile(file) {
        // Validate file type
        const extension = file.name.split('.').pop().toLowerCase();
        if (!this.config.allowedTypes?.includes(extension)) {
            throw new Error(`Tipo de arquivo n√£o suportado: ${extension}`);
        }

        // Validate file size
        const maxSize = this.parseSize(this.config.maxFileSize || '10MB');
        if (file.size > maxSize) {
            throw new Error(`Arquivo muito grande. M√°ximo: ${this.config.maxFileSize}`);
        }

        const content = await this.extractTextFromFile(file);
        const category = await this.categorizeContent(content);
        
        const document = {
            id: Date.now() + Math.random(),
            name: file.name,
            type: extension,
            size: file.size,
            content: content,
            category: category,
            uploadDate: new Date().toISOString(),
            keywords: this.extractKeywords(content)
        };

        this.documents.set(document.id, document);
        this.categories[category].push(document.id);
        
        // Save to localStorage
        this.saveToStorage();
        
        return document;
    }

    async extractTextFromFile(file) {
        const extension = file.name.split('.').pop().toLowerCase();
        
        switch (extension) {
            case 'txt':
                return await file.text();
                
            case 'pdf':
                // For now, return placeholder - PDF parsing would need pdf-parse
                return `[PDF Content] ${file.name} - ${file.size} bytes`;
                
            case 'docx':
                // For now, return placeholder - DOCX parsing would need mammoth
                return `[DOCX Content] ${file.name} - ${file.size} bytes`;
                
            default:
                throw new Error(`Unsupported file type: ${extension}`);
        }
    }

    async categorizeContent(content) {
        // Simple keyword-based categorization
        const text = content.toLowerCase();
        
        const patterns = {
            objections: ['obje√ß√£o', 'pre√ßo', 'caro', 'or√ßamento', 'n√£o temos', 'vamos pensar'],
            scripts: ['script', 'roteiro', 'apresenta√ß√£o', 'abertura', 'fechamento'],
            cases: ['caso', 'sucesso', 'cliente', 'resultado', 'roi', 'economia'],
            questions: ['pergunta', 'quest√£o', 'descoberta', 'necessidade', 'dor']
        };

        for (const [category, keywords] of Object.entries(patterns)) {
            if (keywords.some(keyword => text.includes(keyword))) {
                return category;
            }
        }

        return 'scripts'; // Default category
    }

    extractKeywords(content) {
        // Simple keyword extraction
        const words = content.toLowerCase()
            .replace(/[^\w\s]/g, '')
            .split(/\s+/)
            .filter(word => word.length > 3);
        
        const frequency = {};
        words.forEach(word => {
            frequency[word] = (frequency[word] || 0) + 1;
        });

        return Object.entries(frequency)
            .sort(([,a], [,b]) => b - a)
            .slice(0, 10)
            .map(([word]) => word);
    }

    async searchRelevantContent(conversationContext) {
        if (!this.isEnabled || this.documents.size === 0) {
            return '';
        }

        const query = conversationContext.toLowerCase();
        const relevantDocs = [];

        for (const [id, doc] of this.documents) {
            const score = this.calculateRelevanceScore(query, doc);
            if (score > 0.3) {
                relevantDocs.push({ doc, score });
            }
        }

        // Sort by relevance and take top 3
        relevantDocs.sort((a, b) => b.score - a.score);
        
        return relevantDocs
            .slice(0, 3)
            .map(({ doc }) => `[${doc.category.toUpperCase()}] ${doc.content.slice(0, 200)}...`)
            .join('\n\n');
    }

    calculateRelevanceScore(query, document) {
        const content = document.content.toLowerCase();
        const keywords = document.keywords;
        
        let score = 0;
        
        // Direct text match
        if (content.includes(query)) {
            score += 0.5;
        }
        
        // Keyword match
        const queryWords = query.split(/\s+/);
        for (const word of queryWords) {
            if (keywords.includes(word)) {
                score += 0.2;
            }
        }
        
        return Math.min(score, 1);
    }

    updateCategoryCounts() {
        Object.keys(this.categories).forEach(category => {
            const element = document.getElementById(`${category}-count`);
            if (element) {
                const count = this.categories[category].length;
                element.textContent = `${count} documento${count !== 1 ? 's' : ''}`;
            }
        });
    }

    renderDocumentsList() {
        const container = document.getElementById('documentsList');
        if (!container) return;

        container.innerHTML = '';
        
        for (const [id, doc] of this.documents) {
            const item = document.createElement('div');
            item.className = 'document-item';
            item.innerHTML = `
                <div class="document-icon">${this.getDocumentIcon(doc.type)}</div>
                <div class="document-info">
                    <div class="document-name">${doc.name}</div>
                    <div class="document-meta">${doc.category} ‚Ä¢ ${this.formatFileSize(doc.size)}</div>
                </div>
                <div class="document-actions">
                    <button class="btn-icon" onclick="playbookManager.previewDocument('${id}')" title="Visualizar">üëÅÔ∏è</button>
                    <button class="btn-icon" onclick="playbookManager.deleteDocument('${id}')" title="Excluir">üóëÔ∏è</button>
                </div>
            `;
            container.appendChild(item);
        }
    }

    getDocumentIcon(type) {
        const icons = {
            pdf: 'üìÑ',
            docx: 'üìù',
            txt: 'üìÉ'
        };
        return icons[type] || 'üìÑ';
    }

    formatFileSize(bytes) {
        if (bytes < 1024) return bytes + ' B';
        if (bytes < 1024 * 1024) return Math.round(bytes / 1024) + ' KB';
        return Math.round(bytes / (1024 * 1024)) + ' MB';
    }

    parseSize(sizeStr) {
        const match = sizeStr.match(/^(\d+)(MB|KB|B)$/i);
        if (!match) return 10 * 1024 * 1024; // Default 10MB
        
        const value = parseInt(match[1]);
        const unit = match[2].toUpperCase();
        
        switch (unit) {
            case 'B': return value;
            case 'KB': return value * 1024;
            case 'MB': return value * 1024 * 1024;
            default: return 10 * 1024 * 1024;
        }
    }

    previewDocument(id) {
        const doc = this.documents.get(id);
        if (doc) {
            alert(`Preview: ${doc.name}\n\nCategoria: ${doc.category}\n\nConte√∫do (preview):\n${doc.content.slice(0, 300)}...`);
        }
    }

    deleteDocument(id) {
        const doc = this.documents.get(id);
        if (doc && confirm(`Excluir documento "${doc.name}"?`)) {
            // Remove from category
            const categoryIndex = this.categories[doc.category].indexOf(id);
            if (categoryIndex > -1) {
                this.categories[doc.category].splice(categoryIndex, 1);
            }
            
            // Remove from documents
            this.documents.delete(id);
            
            // Update UI
            this.updateCategoryCounts();
            this.renderDocumentsList();
            this.saveToStorage();
            
            this.updateStatus(`Documento "${doc.name}" exclu√≠do`);
        }
    }

    updateStatus(message) {
        const statusElement = document.getElementById('playbookStatus');
        if (statusElement) {
            statusElement.textContent = message;
        }
    }

    saveToStorage() {
        try {
            const data = {
                documents: Array.from(this.documents.entries()),
                categories: this.categories
            };
            localStorage.setItem('meetPilotPlaybook', JSON.stringify(data));
        } catch (error) {
            console.error('Error saving playbook to storage:', error);
        }
    }

    loadStoredDocuments() {
        try {
            const stored = localStorage.getItem('meetPilotPlaybook');
            if (stored) {
                const data = JSON.parse(stored);
                this.documents = new Map(data.documents || []);
                this.categories = data.categories || this.categories;
                
                this.updateCategoryCounts();
                this.renderDocumentsList();
                
                const docCount = this.documents.size;
                this.updateStatus(`${docCount} documento${docCount !== 1 ? 's' : ''} carregado${docCount !== 1 ? 's' : ''}`);
            }
        } catch (error) {
            console.error('Error loading stored playbook:', error);
            this.updateStatus('Erro ao carregar documentos salvos');
        }
    }
}

// AI Analysis System
class AICoach {
    constructor(apiKey) {
        this.apiKey = apiKey;
        this.conversationBuffer = [];
        this.analysisTimer = null;
        this.lastAnalysis = 0;
        this.analysisInterval = 10000; // Analyze every 10 seconds
        this.suggestions = [];
        this.isAnalyzing = false;
    }

    addTranscription(source, text, timestamp) {
        if (!text || text === '...') return;
        
        this.conversationBuffer.push({
            source, // 'user' or 'meeting'
            text,
            timestamp: timestamp || new Date().toISOString()
        });

        // Keep only last 2 minutes of conversation
        const cutoff = Date.now() - (2 * 60 * 1000);
        this.conversationBuffer = this.conversationBuffer.filter(
            item => new Date(item.timestamp).getTime() > cutoff
        );

        // Trigger analysis if enough time has passed
        if (Date.now() - this.lastAnalysis > this.analysisInterval) {
            this.analyzeConversation();
        }
    }

    async analyzeConversation() {
        if (this.isAnalyzing || this.conversationBuffer.length < 3) return;
        
        this.isAnalyzing = true;
        this.lastAnalysis = Date.now();
        
        try {
            updateAIStatus('Analisando conversa...');
            
            const context = this.buildAnalysisContext();
            const analysis = await this.callOpenAIAnalysis(context);
            
            if (analysis && analysis.suggestions) {
                this.processSuggestions(analysis.suggestions);
            }
            
            updateAIStatus('Pronto para ajudar');
        } catch (error) {
            console.error('AI Analysis error:', error);
            updateAIStatus('Erro na an√°lise - tentando novamente...');
        } finally {
            this.isAnalyzing = false;
        }
    }

    buildAnalysisContext() {
        const recentConversation = this.conversationBuffer
            .slice(-10) // Last 10 exchanges
            .map(item => `[${item.source.toUpperCase()}]: ${item.text}`)
            .join('\n');

        return {
            conversation: recentConversation,
            timestamp: new Date().toISOString(),
            bufferSize: this.conversationBuffer.length
        };
    }

    async callOpenAIAnalysis(context) {
        const prompt = await this.buildAnalysisPrompt(context);
        
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${this.apiKey}`,
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                model: 'gpt-4o-mini',
                messages: [
                    {
                        role: 'system',
                        content: `Voc√™ √© um copiloto de reuni√µes com IA que fornece coaching em tempo real para chamadas de vendas e apresenta√ß√µes. 
                        
                        Analise a conversa e forne√ßa 1-3 sugest√µes curtas e acion√°veis para ajudar o usu√°rio a melhorar sua performance.
                        
                        Foque em:
                        - Identificar obje√ß√µes e sugerir respostas espec√≠ficas
                        - Reconhecer sinais de compra e pr√≥ximos passos
                        - Melhorar engajamento e fluxo da conversa
                        - Sugerir perguntas relevantes ou demonstra√ß√µes
                        - Recomenda√ß√µes de timing
                        - Use o material de apoio fornecido para sugest√µes mais espec√≠ficas
                        
                        Responda APENAS com JSON v√°lido neste formato exato:
                        {
                          "suggestions": [
                            {
                              "type": "objection|opportunity|engagement|next_step",
                              "text": "Sugest√£o acion√°vel curta (m√°x 60 chars)",
                              "priority": "high|medium|low",
                              "context": "Breve explica√ß√£o do porqu√™ esta sugest√£o √© relevante"
                            }
                          ]
                        }`
                    },
                    {
                        role: 'user',
                        content: prompt
                    }
                ],
                max_tokens: 400,
                temperature: 0.7
            })
        });

        if (!response.ok) {
            throw new Error(`OpenAI API error: ${response.status}`);
        }

        const data = await response.json();
        const content = data.choices[0]?.message?.content;
        
        if (!content) {
            throw new Error('No content in OpenAI response');
        }

        try {
            return JSON.parse(content);
        } catch (parseError) {
            console.error('Failed to parse OpenAI response:', content);
            throw new Error('Invalid JSON response from OpenAI');
        }
    }

    async buildAnalysisPrompt(context) {
        let prompt = `Conversa recente:
${context.conversation}

Hor√°rio atual: ${context.timestamp}
Tamanho do buffer: ${context.bufferSize} mensagens`;

        // Add playbook content if available
        if (playbookManager && playbookManager.isEnabled) {
            const relevantContent = await playbookManager.searchRelevantContent(context.conversation);
            if (relevantContent) {
                prompt += `

Material de apoio da base de conhecimento:
${relevantContent}`;
            }
        }

        prompt += `

Analise esta conversa e forne√ßa sugest√µes de coaching para o usu√°rio melhorar sua performance na reuni√£o. Use o material de apoio quando dispon√≠vel para sugest√µes mais espec√≠ficas e acion√°veis.`;

        return prompt;
    }

    processSuggestions(suggestions) {
        // Clear old suggestions
        this.suggestions = [];
        
        // Add new suggestions with timestamps
        suggestions.forEach(suggestion => {
            const enrichedSuggestion = {
                ...suggestion,
                id: Date.now() + Math.random(),
                timestamp: new Date().toISOString(),
                displayed: false
            };
            this.suggestions.push(enrichedSuggestion);
        });

        // Display suggestions in UI
        this.displaySuggestions();
    }

    displaySuggestions() {
        const container = document.getElementById('suggestionsContainer');
        if (!container) return;

        // Clear waiting message
        container.innerHTML = '';

        this.suggestions.forEach((suggestion, index) => {
            if (suggestion.displayed) return;
            
            setTimeout(() => {
                this.createSuggestionCard(suggestion, container);
                suggestion.displayed = true;
            }, index * 500); // Stagger animations
        });
    }

    createSuggestionCard(suggestion, container) {
        const card = document.createElement('div');
        card.className = 'suggestion-card';
        card.dataset.suggestionId = suggestion.id;

        const typeColors = {
            objection: '#EF4444',
            opportunity: '#10B981', 
            engagement: '#3B82F6',
            next_step: '#A259FF'
        };

        const typeIcons = {
            objection: '‚ö†Ô∏è',
            opportunity: 'üí°',
            engagement: 'üéØ',
            next_step: '‚Üí'
        };

        const typeLabels = {
            objection: 'Obje√ß√£o',
            opportunity: 'Oportunidade',
            engagement: 'Engajamento',
            next_step: 'Pr√≥ximo Passo'
        };

        card.innerHTML = `
            <div class="suggestion-type" style="color: ${typeColors[suggestion.type] || '#A259FF'}">
                ${typeIcons[suggestion.type] || 'üí°'} ${typeLabels[suggestion.type] || suggestion.type}
            </div>
            <div class="suggestion-text">${suggestion.text}</div>
            <div class="suggestion-context" style="font-size: 0.8rem; color: var(--text-muted); margin-bottom: 1rem;">
                ${suggestion.context}
            </div>
            <div class="suggestion-actions">
                <button class="btn-small" onclick="copySuggestion('${suggestion.id}')">Copiar</button>
                <button class="btn-small" onclick="dismissSuggestion('${suggestion.id}')">Dispensar</button>
            </div>
        `;

        container.appendChild(card);

        // Auto-remove after 12 seconds
        setTimeout(() => {
            if (card.parentNode) {
                card.style.opacity = '0';
                card.style.transform = 'translateY(-10px)';
                setTimeout(() => {
                    if (card.parentNode) {
                        card.parentNode.removeChild(card);
                    }
                }, 300);
            }
        }, 12000);
    }
}

// Global variables
let microphoneSession = null;
let systemAudioSession = null;
let microphoneSessionConfig = null;
let systemAudioSessionConfig = null;
let microphoneVadTime = 0;
let systemAudioVadTime = 0;
let wavRecorder = new WavRecorder();
let microphoneStream = null;
let systemAudioStream = null;
let aiCoach = null;
let playbookManager = null;

// DOM elements
const micResults = document.getElementById('micResults');
const speakerResults = document.getElementById('speakerResults');
const micStatus = document.getElementById('micStatus');
const micSelect = document.getElementById('micSelect');
const speakerStatus = document.getElementById('speakerStatus');
const recordStatus = document.getElementById('recordStatus');
const startBtn = document.getElementById('startBtn');
const stopBtn = document.getElementById('stopBtn');
const recordBtn = document.getElementById('recordBtn');
const modelSelect = document.getElementById('modelSelect');
const aiStatus = document.getElementById('aiStatus');
const suggestionsContainer = document.getElementById('suggestionsContainer');

// Utility functions
function updateAIStatus(status) {
    if (aiStatus) {
        aiStatus.textContent = status;
    }
}

function copySuggestion(suggestionId) {
    const card = document.querySelector(`[data-suggestion-id="${suggestionId}"]`);
    if (card) {
        const text = card.querySelector('.suggestion-text').textContent;
        navigator.clipboard.writeText(text).then(() => {
            // Visual feedback
            const btn = card.querySelector('button');
            const originalText = btn.textContent;
            btn.textContent = 'Copiado!';
            btn.style.background = 'var(--success)';
            setTimeout(() => {
                btn.textContent = originalText;
                btn.style.background = '';
            }, 1000);
        });
    }
}

function dismissSuggestion(suggestionId) {
    const card = document.querySelector(`[data-suggestion-id="${suggestionId}"]`);
    if (card) {
        card.style.opacity = '0';
        card.style.transform = 'translateY(-10px)';
        setTimeout(() => {
            if (card.parentNode) {
                card.parentNode.removeChild(card);
            }
        }, 300);
    }
}

// Configuration
const CONFIG = {
    API_ENDPOINTS: {
        session: 'https://api.openai.com/v1/realtime/sessions',
        realtime: 'https://api.openai.com/v1/realtime'
    },
    VOICE: 'echo',
    VOICES: ['alloy', 'ash', 'ballad', 'coral', 'echo', 'sage', 'shimmer', 'verse'],
    INITIAL_MESSAGE: {
        text: "The transcription will probably be in English."
    }
};

function updateMicSelect() {
    navigator.mediaDevices.enumerateDevices().then(devices => {
        devices.forEach(device => {
            if (device.kind === 'audioinput') {
                const option = document.createElement('option');
                option.value = device.deviceId;
                option.textContent = device.label;
                micSelect.appendChild(option);
            }
        });
    });
}

// Update status display
function updateStatus(streamType, isConnected) {
    const statusElement = streamType === 'microphone' ? micStatus : speakerStatus;
    const statusCard = statusElement;

    if (isConnected) {
        statusCard.className = 'status-card connected';
        statusCard.querySelector('.status-value').textContent = 'Conectado';
    } else {
        statusCard.className = 'status-card disconnected';
        statusCard.querySelector('.status-value').textContent = 'Desconectado';
    }
}

// Handle messages from microphone session
function handleMicrophoneMessage(parsed) {
    console.log('Received microphone message:', parsed);
    let transcript = null;

    switch (parsed.type) {
        case "transcription_session.created":
            microphoneSessionConfig = parsed.session;
            console.log("microphone session created: " + microphoneSessionConfig.id);
            break;
        case "input_audio_buffer.speech_started":
            transcript = {
                transcript: '...',
                partial: true,
            }
            handleMicrophoneTranscript(transcript);
            break;
        case "input_audio_buffer.speech_stopped":
            transcript = {
                transcript: '...',
                partial: true,
            }
            handleMicrophoneTranscript(transcript);
            microphoneVadTime = performance.now() - microphoneSessionConfig.turn_detection.silence_duration_ms;
            break;
        case "conversation.item.input_audio_transcription.completed":
            const elapsed = performance.now() - microphoneVadTime;
            transcript = {
                transcript: parsed.transcript,
                partial: false,
                latencyMs: elapsed.toFixed(0)
            }
            handleMicrophoneTranscript(transcript);
            break;
    }
}

// Handle messages from system audio session
function handleSystemAudioMessage(parsed) {
    console.log('Received system audio message:', parsed);
    let transcript = null;

    switch (parsed.type) {
        case "transcription_session.created":
            systemAudioSessionConfig = parsed.session;
            console.log("system audio session created: " + systemAudioSessionConfig.id);
            break;
        case "input_audio_buffer.speech_started":
            transcript = {
                transcript: '...',
                partial: true,
            }
            handleSystemAudioTranscript(transcript);
            break;
        case "input_audio_buffer.speech_stopped":
            transcript = {
                transcript: '...',
                partial: true,
            }
            handleSystemAudioTranscript(transcript);
            systemAudioVadTime = performance.now() - systemAudioSessionConfig.turn_detection.silence_duration_ms;
            break;
        case "conversation.item.input_audio_transcription.completed":
            const elapsed = performance.now() - systemAudioVadTime;
            transcript = {
                transcript: parsed.transcript,
                partial: false,
                latencyMs: elapsed.toFixed(0)
            }
            handleSystemAudioTranscript(transcript);
            break;
    }
}

// Handle microphone transcript updates
function handleMicrophoneTranscript(transcript) {
    const text = transcript.transcript;
    if (!text) {
        return;
    }

    const timestamp = new Date().toLocaleTimeString();
    const prefix = transcript.partial ? '' : `[${timestamp}] `;

    if (!transcript.partial) {
        micResults.textContent += `${prefix}${text}\n`;
        micResults.scrollTop = micResults.scrollHeight;
        
        // Send to AI Coach for analysis
        if (aiCoach && text.trim() !== '...') {
            aiCoach.addTranscription('user', text, new Date().toISOString());
        }
    }
}

// Handle system audio transcript updates
function handleSystemAudioTranscript(transcript) {
    const text = transcript.transcript;
    if (!text) {
        return;
    }

    const timestamp = new Date().toLocaleTimeString();
    const prefix = transcript.partial ? '' : `[${timestamp}] `;

    if (!transcript.partial) {
        speakerResults.textContent += `${prefix}${text}\n`;
        speakerResults.scrollTop = speakerResults.scrollHeight;
        
        // Send to AI Coach for analysis
        if (aiCoach && text.trim() !== '...') {
            aiCoach.addTranscription('meeting', text, new Date().toISOString());
        }
    }
}

// Handle errors
function handleError(e, streamType) {
    console.error(`${streamType} session error:`, e);
    alert(`Error (${streamType}): ` + e.message);
    stop();
}

// Start transcription
async function start() {
    try {
        startBtn.disabled = true;
        stopBtn.disabled = false;
        modelSelect.disabled = true;

        // Initialize AI Coach
        if (!aiCoach) {
            aiCoach = new AICoach(window.electronAPI.apiKey);
        }
        updateAIStatus('Inicializando...');

        // Get microphone stream
        microphoneStream = await navigator.mediaDevices.getUserMedia({
            audio: {
                deviceId: {
                    exact: micSelect.value
                }
            },
            video: false
        });

        await window.electronAPI.enableLoopbackAudio();

        // Get display media (system audio)
        const displayStream = await navigator.mediaDevices.getDisplayMedia({
            audio: true,
            video: true
        });

        await window.electronAPI.disableLoopbackAudio();

        // Remove video tracks, keep only audio
        const videoTracks = displayStream.getTracks().filter(t => t.kind === 'video');
        videoTracks.forEach(t => t.stop() && displayStream.removeTrack(t));

        systemAudioStream = displayStream;

        // Create microphone session
        microphoneSession = new Session(window.electronAPI.apiKey, 'microphone');
        microphoneSession.onconnectionstatechange = state => {
            console.log('Microphone connection state:', state);
            updateStatus('microphone', state === 'connected');
        };
        microphoneSession.onmessage = handleMicrophoneMessage;
        microphoneSession.onerror = (e) => handleError(e, 'microphone');

        // Create system audio session
        systemAudioSession = new Session(window.electronAPI.apiKey, 'system_audio');
        systemAudioSession.onconnectionstatechange = state => {
            console.log('System audio connection state:', state);
            updateStatus('speaker', state === 'connected');
        };
        systemAudioSession.onmessage = handleSystemAudioMessage;
        systemAudioSession.onerror = (e) => handleError(e, 'system_audio');

        // Configure sessions
        const sessionConfig = {
            input_audio_transcription: {
                model: modelSelect.value,
                prompt: "",
            },
            turn_detection: {
                type: "server_vad",
                silence_duration_ms: 10,
            }
        };

        // Start transcription with both streams
        await Promise.all([
            microphoneSession.startTranscription(microphoneStream, sessionConfig),
            systemAudioSession.startTranscription(displayStream, sessionConfig)
        ]);

        // Enable record button
        recordBtn.disabled = false;
        updateAIStatus('Ouvindo e pronto para dar dicas');
        console.log('Transcription started for both streams');

    } catch (error) {
        console.error('Error starting transcription:', error);
        alert('Erro ao iniciar transcri√ß√£o: ' + error.message);
        stop();
    }
}

// Stop transcription
function stop() {
    startBtn.disabled = false;
    stopBtn.disabled = true;
    recordBtn.disabled = true;
    modelSelect.disabled = false;

    // Stop AI Coach
    if (aiCoach) {
        aiCoach.conversationBuffer = [];
        aiCoach.suggestions = [];
    }
    updateAIStatus('Sess√£o encerrada');
    
    // Clear suggestions
    if (suggestionsContainer) {
        suggestionsContainer.innerHTML = '<div class="waiting-message">Inicie sua sess√£o de reuni√£o para receber sugest√µes de coaching com IA</div>';
    }

    // Stop recording if active
    if (wavRecorder.isRecording) {
        wavRecorder.stopRecording();
        updateRecordStatus(false);
    }

    microphoneSession?.stop();
    microphoneSession = null;
    microphoneSessionConfig = null;

    systemAudioSession?.stop();
    systemAudioSession = null;
    systemAudioSessionConfig = null;

    // Stop and clean up streams
    microphoneStream?.getTracks().forEach(t => t.stop());
    systemAudioStream?.getTracks().forEach(t => t.stop());
    microphoneStream = null;
    systemAudioStream = null;

    updateStatus('microphone', false);
    updateStatus('speaker', false);
    updateRecordStatus(false);

    const timestamp = new Date().toLocaleTimeString();
    micResults.textContent = `[${timestamp}] Aguardando entrada do microfone...\n`;
    speakerResults.textContent = `[${timestamp}] Aguardando √°udio da reuni√£o...\n`;
}

// Update record status display
function updateRecordStatus(isRecording) {
    const statusCard = recordStatus;
    
    if (isRecording) {
        statusCard.className = 'status-card connected';
        statusCard.querySelector('.status-value').textContent = 'Gravando';
        recordBtn.textContent = 'Parar Grava√ß√£o';
    } else {
        statusCard.className = 'status-card disconnected';  
        statusCard.querySelector('.status-value').textContent = 'Parada';
        recordBtn.textContent = 'Iniciar Grava√ß√£o';
    }
}

// Handle recording button click
async function toggleRecording() {
    if (!wavRecorder.isRecording) {
        try {
            await wavRecorder.startRecording(microphoneStream, systemAudioStream);
            updateRecordStatus(true);
        } catch (error) {
            console.error('Error starting recording:', error);
            alert('Erro ao iniciar grava√ß√£o: ' + error.message);
        }
    } else {
        wavRecorder.stopRecording();
        updateRecordStatus(false);
    }
}

// Add event listeners
startBtn.addEventListener('click', start);
stopBtn.addEventListener('click', stop);
recordBtn.addEventListener('click', toggleRecording);
updateMicSelect();

// Initialize Playbook Manager
playbookManager = new PlaybookManager();

// Cleanup on page unload
window.addEventListener('beforeunload', stop);
